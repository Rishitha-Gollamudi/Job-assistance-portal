{
    "data": [
        [
            "Booz Allen Hamilton",
            "FULLTIME",
            "Tech Excellence Data Engineer, Mid",
            "https://careers.boozallen.com/talent/JobDetail/San-Diego-Tech-Excellence-Data-Engineer-Mid-R0170122/78484",
            "Tech Excellence Data Engineer, Mid\n\nThe Opportunity:\n\nEver-expanding technology like IoT, machine learning, and artificial intelligence means that there\u2019s more structured and unstructured data available today than ever before. As a data engineer, you know that organizing big data can yield pivotal insights when it\u2019s gathered from disparate sources. We need a data professional like you to help our clients find answers in their big data to impact important missions\u2014from fraud detection to cancer research to national intelligence.\n\nAs a big data engineer at Booz Allen, you\u2019ll use your skills and experience to implement data engineering activities on some of the most mission-driven projects in the industry. You\u2019ll develop and deploy the pipelines and platforms that organize and make disparate data meaningful.\n\nHere, you\u2019ll work with a multi-disciplinary team of analysts, data engineers, developers, and data consumers in a fast-paced, agile environment. You\u2019ll sharpen your skills in analytical exploration and data examination while you support the assessment, design, developing, and maintenance of scalable platforms for your clients.\n\nWork with us to use big data for good.\n\nJoin us. The world can\u2019t wait.\n\nYou Have:\u202f\n\u2022 2+ years of experience in a professional work environment\n\u2022 Experience with querying or analyzing data to answer questions and solve problems\n\u2022 Experience with Amazon Web Services\n\u2022 Knowledge of basic concepts in mathematics and statistics\n\u2022 Knowledge of basic principles of ETL pipelines\n\u2022 Knowledge of data storage and retrieval approaches\n\u2022 Knowledge of Cloud environments\n\u2022 Ability to learn a programming language\n\u2022 Secret clearance\n\u2022 Bachelor's degree\n\nNice If You Have:\u202f\n\u2022 Experience with systems engineering or systems administration\n\u2022 Experience with visualizing data to identify or communicate key insights\n\u2022 Experience with Azure\n\u2022 Experience using Lambda in AWS\n\u2022 Experience with Docker, Kubernetes, and Ansible\n\u2022 Experience with Python, GitHub in data science, or related\n\u2022 TS/SCI clearance\n\nClearance:\n\nApplicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required.\n\nCreate Your Career:\n\nGrow With Us\n\nYour growth matters to us\u2014that\u2019s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.\n\nA Place Where You Belong\n\nDiverse perspectives cultivate collective ingenuity. Booz Allen\u2019s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you\u2019ll develop your community in no time.\n\nSupport Your Well-Being\n\nOur comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home.\n\nYour Candidate Journey\n\nAt Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we\u2019ve compiled a list of resources so you\u2019ll know what to expect as we forge a connection with you during your journey as a candidate with us.\n\nCompensation\n\nAt Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.\n\nSalary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $58,300.00 to $133,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n\nWork Model\nOur people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.\n\u2022 If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility.\n\u2022 If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role.\n\nEEO Commitment\n\nWe\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
            "2023-04-25T00:00:00.000Z",
            [
                "2+ years of experience in a professional work environment",
                "Experience with querying or analyzing data to answer questions and solve problems",
                "Experience with Amazon Web Services",
                "Knowledge of basic concepts in mathematics and statistics",
                "Knowledge of basic principles of ETL pipelines",
                "Knowledge of data storage and retrieval approaches",
                "Knowledge of Cloud environments",
                "Ability to learn a programming language",
                "Bachelor's degree",
                "Experience with systems engineering or systems administration",
                "Experience with visualizing data to identify or communicate key insights",
                "Experience with Azure",
                "Experience using Lambda in AWS",
                "Experience with Docker, Kubernetes, and Ansible",
                "Experience with Python, GitHub in data science, or related",
                "TS/SCI clearance"
            ],
            [
                "With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms",
                "Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more",
                "With these benefits, plus the option for flexible schedules and remote and hybrid locations, we\u2019ll support you as you pursue a balanced, fulfilling life\u2014at work and at home",
                "At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being",
                "Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care",
                "The projected compensation range for this position is $58,300.00 to $133,000.00 (annualized USD)"
            ]
        ],
        [
            "Bristol Myers Squibb",
            "FULLTIME",
            "RDC Data Engineer",
            "https://jobs.alpfa.org/job/rdc-data-engineer/68911185/",
            "Working with Us\nChallenging. Meaningful. Life-changing. Those aren't words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You'll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.\n\nBristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us\n\nWorkat the interface of pharma, genomics, and data engineering. The candidate will significantly contribute to the development of modern data services for BMS's research scientists.\n\nJob Description\n\nBristol Myers Squibb seeks a highly motivated Data Engineer to enable data integration efforts in support of data science and computational research efforts. The Data Engineer will be responsible for executing an ambitious digital strategy to support BMS's predictive science capabilities in Research. The successful candidate will partner closely with computational researcher teams,ITleadership, and various technical functions to design and deliver data solutions that streamline access to computing & data, and help scientists derive insight and value from their research.\n\nJob Functions\n\nThe role requires someone who can seamlessly mesh technical knowledge to help navigate R&D cloud, CoLo, andon-premisecomputing needs, including planning, infrastructure design, maintenance, and support.\n\nThe role will lead the development of infrastructure that enables interoperability and comparability of data sets derived from different technologies and biological systems in the context of integrative data analysis. The candidate will create and maintain optimal data pipeline architectures that enable scientific workflow and collaborate with interdisciplinary teams of data curators, software engineers, data scientists and computational biologists as we test new hypotheses through the novel integration of emerging research data types.\n\nThe work will combine careful resource planning and project management with hands-on data manipulation and implementation of data integration workflows.\n\nResponsibilities include, but are not limited to, the following:\n\u2022 Designing and developing an ETL infrastructure to load research data from multiple source systems using languages and frameworks such as Python, R, Docker, Airflow, Glue, etc.\n\u2022 Leading the design and implementation of data services solutions that may include relational, NoSQL and graph database components.\n\u2022 Collaborating with project managers, solution architects, infrastructure teams, and external vendors as needed to support successful delivery of technical solutions.\n\nJob Requirements\n\u2022 Bachelor's Degree with 8+ years of academic / industry experience or master's degree with 6+ years of academic / industry experience or PhD with 3+ years of academic / industry experience in an engineering or biology field or equivalent experience.\n\u2022 Demonstrated high proficiency with current software engineering methodologies, such as Agile SDLC approaches, distributed source code control, project management, issue tracking, and CI/CD tools and processes.\n\u2022 Excellent skills in an object-oriented programming language such as Python or R, and proficiency in SQL\n\u2022 High degree of proficiency in cloud computing\n\u2022 Solid understanding of container strategies such as Docker, Fargate, ECS and ECR.\n\u2022 Excellent skills and deep knowledge of databases such as Postgres, Elasticsearch, Redshift, and Aurora, including distributed database design, SQL vs. NoSQL, and database optimizations\n\u2022 Demonstrated high proficiency with current software engineering methodologies, such as Agile SDLC (Software Development Life Cycle) approaches, distributed source code control, project management, issue tracking, and CI/CD tools and processes.\n\u2022 Strong technical communication skills\n\nThe starting compensation for this jobis a range from $114,000 - $159,000, plus incentive cash and stock opportunities (based on eligibility).\n\nThe starting pay rate takes into account characteristics of the job, such as required skills and the where the job is performed. Final individual compensation will be decided based on demonstrated experience.\n\nFor more on benefits, please visit Working With Us (bms.com).Eligibility for specific benefits listed on our BMS Careers site may vary based on the job and location.\n\n#LI-Hybrid\n\nIf you come across a role that intrigues you but doesn't perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.\n\nUniquely Interesting Work, Life-changing Careers\nWith a single vision as inspiring as \"Transforming patients' lives through science\u2122 \", every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.\n\nOn-site Protocol\nPhysical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.\n\nCOVID-19 Information\nTo protect the safety of our workforce, customers, patients and communities, the policy of the Company requires all employees and workers in the U.S. and Puerto Rico to be fully vaccinated against COVID-19, unless they have received an exception based on an approved request for a medical or religious reasonable accommodation.Therefore, all BMS applicants seeking a role located in the U.S. and Puerto Rico must confirm that they have already received or are willing to receive the full COVID-19 vaccination by their start date as a qualification of the role and condition of employment.This requirement is subject to state and local law restrictions and may not be applicable to employees working in certain jurisdictions such as Montana. This requirement is also subject to discussions with collective bargaining representatives in the U.S.\n\nBMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.\n\nBMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.\n\nAny data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations.",
            "2023-04-22T00:00:00.000Z",
            [
                "Bachelor's Degree with 8+ years of academic / industry experience or master's degree with 6+ years of academic / industry experience or PhD with 3+ years of academic / industry experience in an engineering or biology field or equivalent experience",
                "Excellent skills in an object-oriented programming language such as Python or R, and proficiency in SQL",
                "High degree of proficiency in cloud computing",
                "Solid understanding of container strategies such as Docker, Fargate, ECS and ECR",
                "Excellent skills and deep knowledge of databases such as Postgres, Elasticsearch, Redshift, and Aurora, including distributed database design, SQL vs",
                "NoSQL, and database optimizations",
                "Demonstrated high proficiency with current software engineering methodologies, such as Agile SDLC (Software Development Life Cycle) approaches, distributed source code control, project management, issue tracking, and CI/CD tools and processes",
                "Strong technical communication skills"
            ],
            [
                "The starting compensation for this jobis a range from $114,000 - $159,000, plus incentive cash and stock opportunities (based on eligibility)",
                "The starting pay rate takes into account characteristics of the job, such as required skills and the where the job is performed",
                "For more on benefits, please visit Working With Us (bms.com).Eligibility for specific benefits listed on our BMS Careers site may vary based on the job and location"
            ]
        ],
        [
            "Northrop Grumman",
            "FULLTIME",
            "Principal Data Engineer (San Diego)   ",
            "https://devitjobs.us/jobs/Northrop-Grumman-Principal-Data-Engineer-San-Diego",
            "Principal Data Engineer (San Diego)    Salary: 104600 - 157000 USD per year\n\nAt Northrop Grumman we are looking for a Data engineer!\n\n  \ufe0f Our tech stack:\nAPI, AWS, Cloud, DevOps, Django, Docker, EC2, ETL, Flask, HTTP, JavaScript, Linux, Machine Learning, PyTorch, Python, REST, SQL, Security, Tableau, TensorFlow, Web, pandas, Data\n\n   Rquirements:\n- Bachelor's degree in a Science, Technology, Engineering or Mathematics (STEM) field and 5 years of experience in Data Engineering; OR a Masters degree in Science, Technology, Engineering or Mathematics with 3 years\u2019 experience.\n- Proficiency in MS SQL Server, SQL queries, scripting, and automation.\n- Experience building and maintaining Extraction Transfer Load (ETL) and data migration pipelines.\n- Proficiency in programming languages such as Python and C++.\n- Working knowledge of Python ETL libraries (Pandas, SQL Alchemy).\n- Candidate must be able to obtain and maintain a Top-Secret Security Clearance.\n- Degree in Software Engineering, Computer Science or Data Science (Preferred).\n- Active Secret/ Top Secret Security Clearance (Preferred).\n\n  \u200d    \u200d   Your responsibilities are:\n- Design, develop, and maintain a scalable ETL pipeline- to support Machine Learning developments.\n- Develop and troubleshoot SQL code, stored procedures, functions, tables, and views.\n- Experience in extracting and analyzing data from multiple data sources.\n- Research, evaluate, and determine best fit of tools and techniques for data storage, data mining, data transformation, and data integration.\n- Design, develop, test, and deploy scalable data solutions.\n- Collaborate with external functional organizations for data and system understanding.\n- Consult with customers and stakeholder to clearly define needs and objectives.\n- Communicate project status and results to various levels of leadership.\n\nView this job and over 500 other transparent jobs with salaries (      ) & tech stacks (  \ufe0f) on DevITjobs.us\n\nCategory: Data Developer / Engineer\nLocation address: Lightwave Avenue 9393, San-Diego, United States\n\nSalary: 104600 - 157000 USD per year\n\nBenefits & perks that we offer:\n\nNorthrop Grumman - More about us and the role:\n- Requisition ID: R10094748.\n- Category: Research and Sciences.\n- Location: San Diego, CA, USA.\n- Citizenship Required: United States Citizenship.\n- Clearance Type: Top Secret.\n- Telecommute: No- Teleworking not available for this position.\n- Shift: 1st Shift (United States of America).\n- Travel Required: Yes, 10% of the Time.\n- Relocation Assistance: Relocation assistance may be available.\n- Positions Available: 1.\n- Salary Range: $104,600 USD - $157,000 USD.\n- Employees may be eligible for a discretionary bonus in addition to base pay.\n- Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results.\n- Employees in Vice President or Director positions may be eligible for Long Term Incentives.\n- In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business.\n- The health and safety of our employees and their families is a top priority.\n- The company encourages employees to remain up-to-date on their COVID-19 vaccinations.\n- U.S. Northrop Grumman employees may be required, in the future, to be vaccinated or have an approved disability/medical or religious accommodation, pursuant to future court decisions and/or government action on the currently stayed federal contractor vaccine mandate under Executive Order 14042 https://www.saferfederalworkforce.gov/contractors/.\n- Northrop Grumman is committed to hiring and retaining a diverse workforce.\n- The company is an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class.\n- For our complete EEO/AA and Pay Transparency statement, please visit http://www.northropgrumman.com/EEO.\n- U.S. Citizenship is required for most positions.\n\nAre you looking for Data jobs in San-Diego?",
            "2023-05-11T22:00:00.000Z",
            [
                "Bachelor's degree in a Science, Technology, Engineering or Mathematics (STEM) field and 5 years of experience in Data Engineering; OR a Masters degree in Science, Technology, Engineering or Mathematics with 3 years\u2019 experience",
                "Proficiency in MS SQL Server, SQL queries, scripting, and automation",
                "Experience building and maintaining Extraction Transfer Load (ETL) and data migration pipelines",
                "Proficiency in programming languages such as Python and C++",
                "Working knowledge of Python ETL libraries (Pandas, SQL Alchemy)",
                "Candidate must be able to obtain and maintain a Top-Secret Security Clearance",
                "Citizenship Required: United States Citizenship",
                "U.S. Citizenship is required for most positions"
            ],
            [
                "Salary: 104600 - 157000 USD per year",
                "Telecommute: No- Teleworking not available for this position",
                "Relocation Assistance: Relocation assistance may be available",
                "Salary Range: $104,600 USD - $157,000 USD",
                "Employees may be eligible for a discretionary bonus in addition to base pay",
                "Annual bonuses are designed to reward individual contributions as well as allow employees to share in company results",
                "Employees in Vice President or Director positions may be eligible for Long Term Incentives",
                "In addition, Northrop Grumman provides a variety of benefits including health insurance coverage, life and disability insurance, savings plan, Company paid holidays and paid time off (PTO) for vacation and/or personal business",
                "The health and safety of our employees and their families is a top priority"
            ]
        ],
        [
            "General Atomics Aeronautical Systems, Inc",
            "FULLTIME",
            "Data Scientist Engineer at General Atomics Aeronautical Systems, Inc in San Diego, CA",
            "https://sandiego-ca.geebo.com/jobs-online/view/id/1074684424-data-scientist-engineer-at-/",
            "General Atomics Aeronautical Systems, Inc. (GA-ASI), an affiliate of General Atomics, is a world leader in proven, reliable remotely piloted aircraft and tactical reconnaissance radars, as well as advanced high-resolution surveillance systems. We have an exciting opportunity for a Data Scientist with the Field Operations team located in San Diego, CA (Poway). We are currently creating an application that will automate data streams for our team and are looking for this position to help us develop this process and make proper business decisions from the subsequent analysis. Duties and Responsibilities Under general supervision, this position is responsible for supporting research, product development, and sales efforts with insights gained from analyzing potentially large, unstructured complex datasets. Develop and code software programs, algorithms and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources. Assignments are normally accompanied by general instructions and suggestions, outlining possible approaches, sources or information, and potential problems to be encountered with work reviewed regularly for soundness of technical judgment, overall adequacy and accuracy. Tasks involve the exercise of independent judgment and discretion about matters of significance. Essential Functions Design, develop and program methods, processes and systems to consolidate and analyze unstructured, diverse 'big data' sources to generate actionable insights and solutions for client services and product enhancement. Develop, refine, deploy, and support statistical and machine learning models utilizing state of the art approaches. Communicate insights and findings from analysis and experiments to product, service, and business managers. Recommend solutions to moderately complex technical and procedure issues. Create and utilize moderately complex algorithms and approaches, clean and synthesize training/test data, create/run simulations, and perform analysis of alternatives to best meet stakeholder requirements. Support the development and processes for creation of data pipelines May identify opportunities for product and customer process improvement using statistical and machine learning models to improve the effectiveness of different courses of action. Develop and deploy data visualization in order to communicate moderately complex concepts and data in a simple, actionable manner. Interact with product and service teams to identify questions and issues for data analysis and experiments. Document findings and may make technical presentations to business stakeholders as required. May create proposals, cost estimates, and whitepapers suitable for publication. Represents the organization as a contact with internal and external representatives. Maintain the strict confidentiality of sensitive information. Perform other duties as assigned or required. Responsible for observing all laws, regulations, and other applicable obligations wherever and whenever business is conducted on behalf of the Company. Expected to work in a safe manner in accordance with established operating procedures and practices. Job\nQualifications:\nTypically requires a bachelor's or master's degree in data science, applied mathematics, statistics, computer science, or related technical/quantitative discipline from an accredited institution and two or more years of data science experience with a bachelor's degree. May substitute equivalent experience in lieu of education. Must have a general understanding of data science concepts, principles, and theory with technical experience, demonstrating the application of those concepts. Must possess:\nThe ability to understand new concepts quickly and apply them accurately throughout an evolving environment and organize work assignments to meet established timetables The ability to exercise independent judgment in solving issues of moderate scope and complexity Good organizational, verbal and written communication skills to accurately document, report and present findings Good interpersonal skills to effectively interface with all levels of employees including management and outside representatives Good computer skills. Requires proficiency in Python The ability to work independently or in a team environment is essential, as is the ability to work extended hours and travel as required. Ability to obtain and maintain a DoD security clearance is required U.S. citizenship required Travel:\n0-25% Typically requires a bachelor's or master's degree in data science, applied mathematics, statistics, computer science, or related technical/quantitative discipline from an accredited institution and two or more years of data science experience with a bachelor's degree. May substitute equivalent experience in lieu of education. Must have a general understanding of data science concepts, principles, and theory with technical experience, demonstrating the application of those concepts. Must possess:\nThe ability to understand new concepts quickly and apply them accurately throughout an evolving environment and organize work assignments to meet established timetables The ability to exercise independent judgment in solving issues of moderate scope and complexity Good organizational, verbal and written communication skills to accurately document, report and present findings Good interpersonal skills to effectively interface with all levels of employees including management and outside representatives Good computer skills. Requires proficiency in Python The ability to work independently or in a team environment is essential, as is the ability to work extended hours and travel as required. Ability to obtain and maintain a DoD security clearance is required U.S. citizenship required Travel:\n0-25%\nSalary Range:\n$80K -- $100K\nMinimum Qualification\nData Science & Machine LearningEstimated Salary: $20 to $28 per hour based on qualifications.",
            "2023-04-24T00:00:00.000Z",
            [
                "May substitute equivalent experience in lieu of education",
                "Must have a general understanding of data science concepts, principles, and theory with technical experience, demonstrating the application of those concepts",
                "The ability to understand new concepts quickly and apply them accurately throughout an evolving environment and organize work assignments to meet established timetables The ability to exercise independent judgment in solving issues of moderate scope and complexity Good organizational, verbal and written communication skills to accurately document, report and present findings Good interpersonal skills to effectively interface with all levels of employees including management and outside representatives Good computer skills",
                "Requires proficiency in Python The ability to work independently or in a team environment is essential, as is the ability to work extended hours and travel as required",
                "Ability to obtain and maintain a DoD security clearance is required U.S. citizenship required Travel:",
                "0-25% Typically requires a bachelor's or master's degree in data science, applied mathematics, statistics, computer science, or related technical/quantitative discipline from an accredited institution and two or more years of data science experience with a bachelor's degree",
                "Data Science & Machine LearningEstimated Salary: $20 to $28 per hour based on qualifications"
            ],
            [
                "$80K -- $100K"
            ]
        ],
        [
            "The Henry M. Jackson Foundation",
            "FULLTIME",
            "Data Science Engineer (Hybrid) - Pathology",
            "https://www.gettinghired.com/job/computer-and-mathematical/all/11517114/data-science-engineer-hybrid-pathology",
            "Join the HJF Team!\n\nHJF is seeking a Data Science Engineer to support the Department of Pathology located at either Naval Hospital Camp Pendleton or Naval Medical Center San Diego, CA. HJF provides scientific, technical, and programmatic support services to the Department of Pathology. U.S. Citizenship is Required.\n\nThe incumbent will identify and evaluate data science methods for using natural language processing on medical records data and AI methods for digital pathology. Develops methods to extract, store, and prepare medical records data for de-identification and data abstraction from disparate data sources. Analyses, designs and develops pipelines to train, test, and use machine learning and natural language processing inference models on biomedical data; manages development projects from initial design through testing while providing strategic direction.\n\nNOTE: All HJF employees are required to be fully vaccinated against COVID-19. Proof of vaccination or an approved religious or medical accommodation will be required.\n\nResponsibilities:\n\u2022 Work with technical staff and scientists to identify appropriate software modules and algorithms to solve biomedical research problems including medical records data de-identification and abstraction. Incorporate those modules into pipelines for training and testing inference models.\n\u2022 Develop pipelines to extract, format, merge, and store medical data from both current EHR and archival data sources in a suitable format for de-identification and data abstraction.\n\u2022 Develop training and test sets, train models, and collect and interpret data to evaluate and improve inference model performance.\n\u2022 Develop reproducible build processes, unit tests, smoke tests, and SIT tests, and lead code reviews. Ensure that code is maintained in a repository and meets industry standards for documentation, readability, and maintainability.\n\u2022 Collaborate with scientific staff write up and publish machine learning and AI results and models, develop open-source repositories when appropriate, and document code and pipelines in a way that they can be shared with other researchers.\n\u2022 Maintain HIPAA compliance for all patient data, complying with DHA rules and data sharing agreements. Manually confirm de-identification of subsets of data in accordance with HIPAA regulations.\n\u2022 May perform other duties and responsibilities as assigned or directed by the supervisor. This may include attendance of and participation in required training for role.\n\nRequired Knowledge, Skills and Abilities:\n\u2022 Expert at programming in Python and JavaScript, knowledge of SQL and understanding of relational databases.\n\u2022 Detailed knowledge of how to select, train, test, and evaluate the performance of AI, and natural language processing models.\n\u2022 Knowledge of how to develop and test a full pipeline for data processing through a machine learning model on both local machines and in cloud environments.\n\nMinimum Education: Bachelor's degree in Data science or computer science required. Master's degree preferred.\n\nMinimum Experience/ Training Requirements: Minimum 3-5 years of experience required.\n\nPhysical Capabilities: Requires lifting materials up to 20 lbs.\n\nWork Environment: Set in an office work environment.\n\nWork Arrangement: This is a hybrid work environment with flexibility to telework a few days per week.\n\nBackground/Security: U.S. citizenship required; eligible to obtain and maintain a Tier I investigation/ Public Trust and a Common Access Card (CAC).\n\nEmployment with HJF is contingent upon successful completion of a background check, which may include, but is not limited to, contacting your professional references, verification of previous employment, addresses, education, and credentials, a criminal background check, drug screening, and a department of motor vehicle (DMV) check.\n\nAny qualifications to be considered as equivalents, in lieu of stated minimums, require the prior approval of the Chief Human Resources Officer.",
            "2023-04-14T14:17:42.000Z",
            [
                "Expert at programming in Python and JavaScript, knowledge of SQL and understanding of relational databases",
                "Detailed knowledge of how to select, train, test, and evaluate the performance of AI, and natural language processing models",
                "Knowledge of how to develop and test a full pipeline for data processing through a machine learning model on both local machines and in cloud environments",
                "Minimum Education: Bachelor's degree in Data science or computer science required",
                "Minimum Experience/ Training Requirements: Minimum 3-5 years of experience required",
                "Physical Capabilities: Requires lifting materials up to 20 lbs",
                "Background/Security: U.S. citizenship required; eligible to obtain and maintain a Tier I investigation/ Public Trust and a Common Access Card (CAC)",
                "Employment with HJF is contingent upon successful completion of a background check, which may include, but is not limited to, contacting your professional references, verification of previous employment, addresses, education, and credentials, a criminal background check, drug screening, and a department of motor vehicle (DMV) check",
                "Any qualifications to be considered as equivalents, in lieu of stated minimums, require the prior approval of the Chief Human Resources Officer"
            ],
            "No benefits data available"
        ],
        [
            "Upstart",
            "FULLTIME",
            "Director of Data Engineering(Remote)",
            "https://jobs.fox5sandiego.com/jobs/director-of-data-engineeringremote-san-diego-california/987966724-2/",
            "Upstart is a leading AI lending marketplace partnering with banks and credit unions to expand access to affordable credit. By leveraging Upstarts AI marketplace, Upstart-powered banks and credit unions can have higher approval rates and lower loss rates across races, ages, and genders, while simultaneously delivering the exceptional digital-first lending experience their customers demand. Our offerings include personal, auto, and small business loans, and we plan to expand into more verticals as our business grows.\n\nUpstart is a digital-first company, which means that most Upstarters can live and work anywhere in the U.S. We also have offices in San Mateo, CA; Columbus, OH; and Austin, TX.\n\nMost Upstarters join us because they connect with our mission of enabling access to effortless credit based on true risk. If you are energized by the impact you can make at Upstart, we'd love to hear from you!\n\nThe Team\n\nUpstart is the first company to leverage Machine Learning to price credit, Data is a core part of the company's DNA. As our product portfolio has grown and matured, our data needs have greatly increased.\n\nAs the Director of Data Engineering, you will be responsible for building a modern platform that supports the company's analytic needs over the next 3-5 years.\n\nPosition Location - This role is available in the following locations: US Remote, San Mateo, Columbus\n\nTime Zone Requirements - This team operates on the East/West Coast time zones.\n\nTravel Requirements - This team has regular on-site collaboration sessions. These occur 5 days per Month/Quarter at one of our office locations. If you need to travel to make these meetups, Upstart will cover all travel related expenses.\n\nHow you'll make an impact:\n\u2022 Partner across Product Management, Engineering, Analytics, ML to define and execute on a data strategy for our reporting, analytical, and ML capabilities\n\u2022 Work with internal engineering and external vendor teams to build the company's data platform\n\u2022 Partner with our recruiting team to build a diverse team of world-class engineers\n\u2022 Coach engineers and managers through career and skill development\n\nWhat we're looking for:\n\nMinimum requirements:\n\u2022 BS in Computer Science or equivalent experience\n\u2022 10+ years of engineering management experience and 15+ years overall software engineering experience\n\u2022 5+ years experience with cloud technologies\n\u2022 5+ years experience with building data/analytic platforms\n\nPreferred qualifications:\n\u2022 PhD in Computer Science/Data Science/Machine Learning\n\u2022 Expertise in cloud native big data and analytics platform technologies\n\u2022 A track record of attracting and developing world-class engineering talent\n\u2022 Excellent communication skills: verbal and written\n\u2022 Well versed in agile development methodologies\n\u2022 Comfortable working with remote teams across all US timezones\n\u2022 Interest in being part of a dynamic and fast paced environment\n\nWhat youll love:\n\u2022 Competitive Compensation (base + bonus & equity)\n\u2022 Comprehensive medical, dental, and vision coverage\n\u2022 Personal Development and Technology & Ergonomic Budgets\n\u2022 Life insurance and disability benefits\n\u2022 Clubs and Activities (Game Nights, Fitstarters, Superwomen, Book Club, Investing Club, Money Discussions, Photography Club and Basketball teams)\n\u2022 Generous vacation policy\n\u2022 401(k) and Employee Stock Purchase Plan (ESPP)\n\u2022 Catered lunches + snacks & drinks\n\nAt Upstart, your base pay is one part of your total compensation package. The anticipated base salary for this position is expected to be within this range: $190,400 - $280,000. Your actual base pay will depend on your geographic location-with our digital first philosophy, Upstart uses compensation regions that vary depending on location. Individual pay is also determined by job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.\n\nIn addition, Upstart provides employees with target bonuses, equity compensation, and generous benefits packages (including medical, dental, vision, and 401k). Sales positions generally offer a competitive On Target Earnings (OTE) incentive compensation structure. The salary listed above for sales roles is OTE, which includes both salary and commission, assuming 100% target achievement.",
            "2023-04-25T20:17:12.000Z",
            [
                "BS in Computer Science or equivalent experience",
                "10+ years of engineering management experience and 15+ years overall software engineering experience",
                "5+ years experience with cloud technologies",
                "5+ years experience with building data/analytic platforms"
            ],
            [
                "Competitive Compensation (base + bonus & equity)",
                "Comprehensive medical, dental, and vision coverage",
                "Personal Development and Technology & Ergonomic Budgets",
                "Life insurance and disability benefits",
                "Clubs and Activities (Game Nights, Fitstarters, Superwomen, Book Club, Investing Club, Money Discussions, Photography Club and Basketball teams)",
                "Generous vacation policy",
                "401(k) and Employee Stock Purchase Plan (ESPP)",
                "Catered lunches + snacks & drinks",
                "At Upstart, your base pay is one part of your total compensation package",
                "The anticipated base salary for this position is expected to be within this range: $190,400 - $280,000",
                "Your actual base pay will depend on your geographic location-with our digital first philosophy, Upstart uses compensation regions that vary depending on location",
                "Individual pay is also determined by job-related skills, experience, and relevant education or training",
                "Your recruiter can share more about the specific salary range for your preferred location during the hiring process",
                "In addition, Upstart provides employees with target bonuses, equity compensation, and generous benefits packages (including medical, dental, vision, and 401k)",
                "Sales positions generally offer a competitive On Target Earnings (OTE) incentive compensation structure",
                "The salary listed above for sales roles is OTE, which includes both salary and commission, assuming 100% target achievement"
            ]
        ],
        [
            "Booz Allen Hamilton",
            "FULLTIME",
            "Data Engineer, Mid",
            "https://careers.boozallen.com/talent/JobDetail/San-Diego-Data-Engineer-Mid-R0167655/76992",
            "Data Engineer, Mid\n\nThe Challenge:\n\nDo you want to work at the forefront of advanced technology and solve complex data challenges? You know that data yields pivotal insights when it\u2019s gathered from disparate sources and organized. As a data engineer, you have the chance to develop and deploy the pipelines and platforms that make this data meaningful. What\u2019s more, you\u2019ll have the chance to help grow Booz Allen\u2019s DataOps capabilities while working with a multi-disciplinary team of analysts, data scientists, developers, and data consumers in a fast-paced, Agile environment. We\u2019re looking for someone like you to work with our clients and meet their mission by developing the next generation of IT Infrastructure.\n\nThis is an opportunity to implement data engineering activities on some of the most mission-driven projects in the industry. Supporting tactical and strategic data infrastructure, you\u2019ll have the chance to architect data systems, stand up data platforms, build out extract, transform, and load pipelines, write custom code, interface with data stores, perform ingestion, and deploy models. From sharing your skills in analytical exploration and examination of data to supporting the assessment, design, building, and maintenance of scalable platforms, you\u2019ll work with our clients to solve their most pressing challenges.\n\nReady to help drive innovation using cutting-edge data tools and techniques?\n\nJoin us. The world can\u2019t wait.\n\nYou Have:\n\u2022 1+ years of experience with writing software in programming languages, including Python\n\u2022 1+ years of experience with source control and collaboration software, including Git or Atlassian tools\n\u2022 1+ years of experience with ETL operations, including on-premises or Cloud infrastructure\n\u2022 Knowledge of relational and non-relational database technologies, including SQL or GraphQL\n\u2022 Knowledge of automation and scripting on Linux or Windows operating systems\n\u2022 Ability to obtain a security clearance\n\u2022 Bachelor's degree\n\nNice If You Have:\n\u2022 Experience with deploying analytics workloads on platform as a service (PaaS) and software as a service (SaaS), including AWS EMR, Redshift, SageMaker, Azure Databricks, SQL Data Warehouse, or Machine Learning service\n\u2022 Experience with distributed or parallel programming frameworks, including Apache Spark or NVIDIA CUDA\n\u2022 Experience with infrastructure as code frameworks and services, including Terraform or CloudFormation\n\u2022 Experience with developing and presenting complex technical information for technical and non-technical audiences and senior leaders\n\u2022 Experience with developing and deploying large-scale batch and stream analytics pipelines\n\u2022 Experience working with integrated groups comprised of customer success managers, infrastructure engineers, data scientists, and software engineers\n\u2022 Experience with DoD information systems\n\u2022 Master\u2019s degree in Mathematics\n\u2022 Cloud Development Certification, including AWS Solutions Architect or Azure certification\n\u2022 Information Security Certification, including Security+ or CISSP certification\n\nClearance:\n\nApplicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.\n\nBuild Your Career:\n\nAt Booz Allen, we know the power of analytics and we\u2019re dedicated to helping you grow as a data analysis professional. When you join Booz Allen, you\u2019ll have the chance to:\n\u2022 access online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk\n\u2022 change the world with the Data Science Bowl\u2014the world\u2019s premier data science for social good competition\n\u2022 participate in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government\n\nYou\u2019ll have access to a wealth of training resources through our Analytics University, an online learning portal specifically geared towards data science and analytics skills, where you can access more than 5000 functional and technical courses, certifications, and books. Build your technical skills through hands-on training on the latest tools and state-of-the-art tech from our in-house experts. Pursuing certifications that directly impact your role? You may be able to take advantage of our tuition assistance, on-site bootcamps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips. We\u2019ll help you develop the career you want as you chart your own course for success.\n\nCompensation\n\nAt Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen\u2019s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.\n\nSalary at Booz Allen is determined by various factors, including but not limited to location, the individual\u2019s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $58,300.00 to $133,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen\u2019s total compensation package for employees.\n\nWork Model\nOur people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.\n\u2022 If this position is listed as remote or hybrid, you\u2019ll periodically work from a Booz Allen or client site facility.\n\u2022 If this position is listed as onsite, you\u2019ll work with colleagues and clients in person, as needed for the specific role.\n\nEEO Commitment\n\nWe\u2019re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change \u2013 no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",
            "2023-03-24T00:00:00.000Z",
            [
                "1+ years of experience with writing software in programming languages, including Python",
                "1+ years of experience with source control and collaboration software, including Git or Atlassian tools",
                "1+ years of experience with ETL operations, including on-premises or Cloud infrastructure",
                "Knowledge of relational and non-relational database technologies, including SQL or GraphQL",
                "Knowledge of automation and scripting on Linux or Windows operating systems",
                "Ability to obtain a security clearance",
                "Bachelor's degree",
                "Experience with deploying analytics workloads on platform as a service (PaaS) and software as a service (SaaS), including AWS EMR, Redshift, SageMaker, Azure Databricks, SQL Data Warehouse, or Machine Learning service",
                "Experience with distributed or parallel programming frameworks, including Apache Spark or NVIDIA CUDA",
                "Experience with infrastructure as code frameworks and services, including Terraform or CloudFormation",
                "Experience with developing and presenting complex technical information for technical and non-technical audiences and senior leaders",
                "Experience with developing and deploying large-scale batch and stream analytics pipelines",
                "Experience working with integrated groups comprised of customer success managers, infrastructure engineers, data scientists, and software engineers",
                "Experience with DoD information systems",
                "Master\u2019s degree in Mathematics",
                "Cloud Development Certification, including AWS Solutions Architect or Azure certification",
                "Information Security Certification, including Security+ or CISSP certification"
            ],
            [
                "You may be able to take advantage of our tuition assistance, on-site bootcamps, certification training, academic programs, vendor relationships, and a network of professionals who can give you helpful tips",
                "At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being",
                "Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care",
                "The projected compensation range for this position is $58,300.00 to $133,000.00 (annualized USD)"
            ]
        ],
        [
            "Strateos",
            "FULLTIME",
            "Scientific Data Automation Engineer",
            "https://www.linkedin.com/jobs/view/scientific-data-automation-engineer-at-strateos-3498959737",
            "We Are\n\nStrateos has reimagined laboratories as smart data generation centers with the industry\u2019s first Cloud Lab Automation-as-a-Service Platform. Strateos enables scientists to design, run, and analyze experiments achieving new and faster scientific discoveries. Our mission is to create new knowledge driven by data, computation, artificial intelligence, automation software, and high-throughput robotics with the goal of fundamentally advancing the life sciences.\n\u2022 Our remote control and automated cloud labs are accessible from a web browser enabling\n\u2022 scientists around the world to easily access and control small and large molecule, cell and gene\n\u2022 therapy and synthetic biology workflows.\n\u2022 Our smart lab facility design-build services and lab automation software enables organizations\n\u2022 to control their own scientific instruments and laboratories locally and worldwide, schedule\n\u2022 workflows and manage their scientific data.\n\nWe Want\n\nWe are looking for a highly motivated Scientific Data Automation Engineer to join our team. In this role, you will facilitate handling of scientific data flows between different data platforms and develop novel tools in cheminformatics and bioinformatics space. The tasks will include writing scripts connecting different platforms via APIs, developing novel algorithms for data processing and decision making, establishing infrastructure for novel data workflows, train various stakeholders at Strateos in these emerging technologies, facilitate integration of developed algorithms into Strateos full-stack software. Excellent understanding of programming logic and various programming languages is essential in this role. Track record of developing experimental algorithms is necessary. Application of mathematical models and data processing scripts in orthogonal fields is important. A large variety of example scripts uploaded on GitHub is a plus. Preference will be given to candidates with experience in both algorithm development and effective communications.\n\nTechnical Skills\n\u2022 Understanding of relational and graph databases (Neo4j is a plus)\n\u2022 Experience in development of multi-actor data processing systems\n\u2022 Knowledge of building distributed systems, AI or machine learning\n\u2022 Demonstrated experience with at least one script language (Python preferred)\n\u2022 Experience in services scale up\n\nPeople Skills\n\u2022 Strong organizational skills\n\u2022 Ability to provide technical training\n\u2022 Ability to track multiple parallel projects\n\u2022 Ability to thrive in a team and goal driven environment\n\u2022 Excellent verbal and written communicator\n\nYou Have\n\u2022 A Bachelor\u2019s or Master\u2019s degree in Mathematics, Physics or Computer Sciences with 2-10 years of algorithm development experience OR PhD in Mathematics, Physics or\n\u2022 Computer Sciences with algorithm development experience\n\u2022 Demonstrated commitment to individual productivity in a fast-paced environment\n\u2022 Experience working as part of a diverse team\n\u2022 A passion for new automation and decision-making technologies\n\nYou May Have\n\u2022 Deep interest in learning drug development, robotic automation, chemistry, and biology\n\u2022 A collection of developed scripts in your personal GitHub account\n\u2022 Experience working with scientists and/or scientific algorithms\n\u2022 Knowledge of web backend and frontend programming\n\nYou Want\n\u2022 A challenging environment that will push you to grow and improve professionally, every\n\u2022 day\n\u2022 The ability to learn unique skills on the job\n\u2022 Freedom to work on state-of-the-art technology and real science\n\u2022 Ability to develop on one of the most advanced automated chemistry platforms on the\n\u2022 planet\n\u2022 Competitive salary and meaningful equity\n\u2022 Flexible vacation policy\n\u2022 Medical, dental, vision and life insurance\n\u2022 401k matching\n\nStrateos is an equal opportunity employer",
            "2023-04-03T15:25:24.000Z",
            [
                "Excellent understanding of programming logic and various programming languages is essential in this role",
                "Track record of developing experimental algorithms is necessary",
                "Application of mathematical models and data processing scripts in orthogonal fields is important",
                "Preference will be given to candidates with experience in both algorithm development and effective communications",
                "Experience in development of multi-actor data processing systems",
                "Knowledge of building distributed systems, AI or machine learning",
                "Experience in services scale up",
                "Strong organizational skills",
                "Ability to provide technical training",
                "Ability to track multiple parallel projects",
                "Ability to thrive in a team and goal driven environment",
                "Excellent verbal and written communicator",
                "A Bachelor\u2019s or Master\u2019s degree in Mathematics, Physics or Computer Sciences with 2-10 years of algorithm development experience OR PhD in Mathematics, Physics or",
                "Demonstrated commitment to individual productivity in a fast-paced environment",
                "Experience working as part of a diverse team",
                "A passion for new automation and decision-making technologies",
                "Deep interest in learning drug development, robotic automation, chemistry, and biology",
                "A collection of developed scripts in your personal GitHub account",
                "Experience working with scientists and/or scientific algorithms",
                "Knowledge of web backend and frontend programming",
                "The ability to learn unique skills on the job",
                "Freedom to work on state-of-the-art technology and real science",
                "Ability to develop on one of the most advanced automated chemistry platforms on the"
            ],
            [
                "A challenging environment that will push you to grow and improve professionally, every",
                "Competitive salary and meaningful equity",
                "Flexible vacation policy",
                "Medical, dental, vision and life insurance",
                "401k matching"
            ]
        ],
        [
            "AppFolio",
            "FULLTIME",
            "Data Engineer",
            "https://www.theladders.com/job/data-engineer-appfolio-san-diego-ca_63180898",
            "What we\u2019re looking for\n\nThe Data Engineer will contribute to our growing Data Engineering and Operations team. We work collaboratively to develop an infrastructure that ingests data from disparate sources and routes them to various destinations, thus providing access to high quality data to users, ranging from application developers interested in specific events to data analysts keen on business intelligence to data scientists training ML models.\n\nAt AppFolio, we paddle as one. We ride and make waves together, with a relentless focus on building great products for the way our customers work and live today \u2013 and tomorrow. AppFolio is a destination organization where careers are made and accelerated. Here, innovation is a team sport.\n\nYour impact\n\u2022 Design, build, deploy, and operate next generation data pipeline infrastructure based on Apache Kafka and its ecosystem\n\u2022 Improve data architecture, quality, discoverability and access policies to enable and enforce data governance\n\u2022 Collaborate with engineers, data analysts and scientists to ensure that our data infrastructure meets the SLOs of our data-intensive customers\n\u2022 Develop techniques for monitoring the completeness, correctness and reliability of our data sets\n\u2022 Leverage agile practices, encourage collaboration, prioritization, and urgency to develop at a rapid pace\n\u2022 Research, share, and recommend new technologies and trends\n\nQualifications\n\u2022 You have hands-on experience with using Apache Kafka in production and have a passion for building a reliable, scalable and fault-tolerant infrastructure.\n\u2022 You have hands-on experience with data warehouse technology, particularly with Snowflake.\n\u2022 You have worked with a variety of data sources, including change data capture systems, event sourcing and clickstreams, in production.\n\u2022 You care about work-life balance and want your company to care about it too; you'll put in the extra hour when needed but won't let it become a habit.\n\u2022 You want to work with a high degree of autonomy, while at the same time working on initiatives of high importance to the company.\n\nMust have\n\u2022 You have 3+ years of experience working with languages like Python or Ruby.\n\u2022 You have excellent SQL skills.\n\u2022 You have 2+ years of experience working with Infrastructure as Code, configuration management, and monitoring tools.\n\u2022 Experience with Kafka Connect, or Kafka Stream\n\nNice to have\n\u2022 Experience with Debezium connector is highly desirable.\n\u2022 Experience with clickstream tracking technology in general, or Snowplow in particular, is desirable.\n\u2022 Experience with containers and container orchestration tools. Docker and Kubernetes experience in particular is desirable.\n\u2022 Experience in visualization tools like tableau\n\nCompensation & Benefits\n\nThe base salary/hourly wage that we reasonably expect to pay for this role is: $106,000 to $160,000.\n\nThe actual base salary/hourly wage for this role will be determined by a variety of factors, including but not limited to: the candidate\u2019s skills, education, experience, etc.\n\nPlease note that base pay is one important aspect of a compelling Total Rewards package. The base pay range indicated here does not include any additional benefits or bonuses/commissions that you may be eligible for based on your role and/or employment type.\n\nRegular full-time employees are eligible for benefits including but not limited to:\n\u2022 Paid Time Off (PTO)\n\u2022 Medical, dental, and vision benefits\n\u2022 Long-term and short-term disability insurance\n\u2022 401(k)\n\u2022 Wellness benefits\n\nInterns / full-time temporary / eligible variable hour employees are eligible for benefits including but not limited to:\n\u2022 Medical\n\u2022 401(k)\n\u2022 Wellness benefits\n\nWhy AppFolio\n\nWe ride and make waves together, with a relentless focus on building great products for the way our customers work and live today \u2014 and tomorrow. AppFolio is a destination organization where careers are made and accelerated. Here, innovation is a team sport.\n\nPaddle as One.\n\nWhy AppFolio\n\nWe ride and make waves together, with a relentless focus on building great products for the way our customers work and live today \u2014 and tomorrow. AppFolio is a destination organization where careers are made and accelerated. Here, innovation is a team sport.\n\nPaddle as One.\n\nStatement of Equal Opportunity\n\nAt AppFolio, we value diversity in backgrounds and perspectives and depend on it to drive our innovative culture. That\u2019s why we\u2019re a proud Equal Opportunity Employer, and we believe that our products, our teams, and our business are stronger because of it. This means that no matter what race, color, religion, sex, sexual orientation, gender identification, national origin, age, marital status, ancestry, physical or mental disability, or veteran status, you\u2019re always welcome at AppFolio.",
            "2023-04-25T06:55:48.000Z",
            [
                "You have hands-on experience with using Apache Kafka in production and have a passion for building a reliable, scalable and fault-tolerant infrastructure",
                "You have hands-on experience with data warehouse technology, particularly with Snowflake",
                "You have worked with a variety of data sources, including change data capture systems, event sourcing and clickstreams, in production",
                "You care about work-life balance and want your company to care about it too; you'll put in the extra hour when needed but won't let it become a habit",
                "You want to work with a high degree of autonomy, while at the same time working on initiatives of high importance to the company",
                "You have 3+ years of experience working with languages like Python or Ruby",
                "You have excellent SQL skills",
                "You have 2+ years of experience working with Infrastructure as Code, configuration management, and monitoring tools",
                "Experience with Kafka Connect, or Kafka Stream",
                "Experience with containers and container orchestration tools",
                "Experience in visualization tools like tableau"
            ],
            [
                "The base salary/hourly wage that we reasonably expect to pay for this role is: $106,000 to $160,000",
                "The actual base salary/hourly wage for this role will be determined by a variety of factors, including but not limited to: the candidate\u2019s skills, education, experience, etc",
                "The base pay range indicated here does not include any additional benefits or bonuses/commissions that you may be eligible for based on your role and/or employment type",
                "Paid Time Off (PTO)",
                "Medical, dental, and vision benefits",
                "Long-term and short-term disability insurance",
                "401(k)",
                "Wellness benefits",
                "Interns / full-time temporary / eligible variable hour employees are eligible for benefits including but not limited to:"
            ]
        ],
        [
            "Scientific Research Corporation",
            "FULLTIME",
            "Data Flow Engineer",
            "https://www.ziprecruiter.com/c/Scientific-Research-Corporation/Job/Data-Flow-Engineer/-in-San-Diego,CA?jid=ae21e8491106aa54",
            "Job Description\n\nPRIMARY DUTIES RESPONSIBILITIES:\n\nThe Data Flow Engineer will be a member of a Cryptologic Carry-On Program (CCOP) and Ship's Signals Exploitation Equipment (SSEE) Systems Engineering team primarily responsible for ensuring the processing and distribution of data to and from intelligence community networks.\nThe ideal candidate will have a history of direct involvement with successful NiFi data flow engineering and resolving Navy hardware and software functionality problems by providing a high degree of timely customer service and technical expertise in support of the US Navy information warfare community.\n\u2022 Installs, configures, integrates, and maintains NiFi servers and processors into new or existing system architectures.\n\u2022 Verifies and maintains all NiFi processors and flows to and from deployed (and test) systems, from the field system through customer back-end repositories\n\u2022 Assists end users with the operational readiness and configuration of deployed systems for optimal data flow to satisfy customer requirements\n\u2022 Designs and develops NiFi processors and flows for deployed systems, containing multiple subsystems and requiring integration with external networks\n\u2022 Implements expression language in NiFi processors in response to emerging customer requirements\n\u2022 Exhibits developed verbal and written communication skills and the ability to express concepts and ideas in a clear and concise manner; employing technical writing techniques\n\u2022 Must be a team player, dedicated to the endeavors of the mission, the customer, and the team itself\n\u2022 Is self-starter who is accountable and requires minimal direction and supervision; capable of multitasking and working several complex and diverse tasks with simultaneous or near simultaneous deadlines\n\nRequirements\n\nMINIMUM SKILLS REQUIREMENTS:\n\u2022 Must possess an active TS/SCI clearance w/CI Polygraph\n\u2022 Bachelor's degree in related technical field or equivalent work experience\n\u2022 One to three (1-3) years of Apache Niagara Files (NiFi) experience (negotiable with other qualifications)\n\u2022 Intermediate Linux Command Line Interface (CLI) experience\n\u2022 Strong background in using and troubleshooting software defined radio (SDR) systems\n\u2022 Fundamental knowledge of wireless protocols in common use\n\u2022 Experience providing technical support to customers over Internet Relay Chat (IRC) or similar applications\n\u2022 Familiarity with back-end databases and repositories\n\u2022 Must be willing to travel up to 15% of the year\n\u2022 Must currently be DoD 8570-compliant with the equivalent of an IAT II certification or have the ability to do so within 6 months of employment\n\nDESIRED SKILLS REQUIREMENTS:\n\u2022 Current Linux+/LPIC 1 and/or Network+ certification\n\u2022 Familiarity with Regular Expression (REGEX), Cisco Networking, Amazon Web Services (AWS)\n\u2022 Expert-level SDR knowledge and experience\n\u2022 Experience with strategic-level intelligence processes\n\u2022 Computer programing experience (i.e. Python, Javascript, bash)\n\u2022 Experience as an instructor\n\u2022 Prior Navy CTR/CTM/CTN with Shipborne, Expeditionary, or other comparable experience\n\nSRC IS A CONTRACTOR FOR THE U.S. GOVERNMENT, THIS POSITION WILL REQUIRE U.S. CITIZENSHIP AS WELL AS, A U.S. GOVERNMENT SECURITY CLEARANCE AT THE TOP SECRET / SCI with CI POLY LEVEL\n\nABOUT US\n\nScientific Research Corporation is an advanced information technology and engineering company that provides innovative products and services to government and private industry, as well as independent institutions. At the core of our capabilities is a seasoned team of highly skilled engineers and scientists with multidisciplinary backgrounds. This team is challenged daily to provide cutting edge technology solutions to our clients.\n\nScientific Research Corporation offers a competitive salary, an extensive benefits package and a work environment that encourages excellence. For positions requiring a security clearance, selected applicants will be subject to a government security investigation and must meet eligibility requirements for access to classified information.\n\nDIVERSITY INCLUSION\n\nWe strongly believe in the abundance of differences among individuals. We value different points of view and appreciate diverse perspectives. We truly believe this is what makes our organization inclusive and more responsive to the needs of our diverse customers.\n\nEQUAL OPPORTUNITY EMPLOYER\n\nScientific Research Corporation is an equal opportunity and affirmative action employer that does not discriminate in employment.\n\nAll qualified applicants will receive consideration for employment without regard to their race, color, religion, sex, age, sexual orientation, gender identity, or national origin, disability or protected veteran status.\n\nScientific Research Corporation endeavors to make www.scires.com accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact srchr@scires.com for assistance. This contact information is for accommodation requests only and cannot be used to inquire about the status of applications.\n\nCovid 19\n\nSRC does not currently require COVID-19 vaccinations for its employees. Pending the outcome of various court proceedings and resultant government action, SRC and all other Federal Contractor employees may be required, at some point in the future, to be fully vaccinated subject to accommodations for valid medical or religious reasons. Please visit https://www.saferfederalworkforce.gov/contractors/ to read more about the Federal Government's current position on COVID-19 vaccines for Federal Contractor employees.",
            "2023-04-21T00:00:00.000Z",
            [
                "Must possess an active TS/SCI clearance w/CI Polygraph",
                "Bachelor's degree in related technical field or equivalent work experience",
                "One to three (1-3) years of Apache Niagara Files (NiFi) experience (negotiable with other qualifications)",
                "Intermediate Linux Command Line Interface (CLI) experience",
                "Strong background in using and troubleshooting software defined radio (SDR) systems",
                "Fundamental knowledge of wireless protocols in common use",
                "Experience providing technical support to customers over Internet Relay Chat (IRC) or similar applications",
                "Familiarity with back-end databases and repositories",
                "Must be willing to travel up to 15% of the year",
                "Must currently be DoD 8570-compliant with the equivalent of an IAT II certification or have the ability to do so within 6 months of employment",
                "Python, Javascript, bash)",
                "Experience as an instructor",
                "Prior Navy CTR/CTM/CTN with Shipborne, Expeditionary, or other comparable experience",
                "CITIZENSHIP AS WELL AS, A U.S. GOVERNMENT SECURITY CLEARANCE AT THE TOP SECRET / SCI with CI POLY LEVEL"
            ],
            "No benefits data available"
        ]
    ]
}